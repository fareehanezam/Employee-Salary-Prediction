{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR_Mpn98kMvf",
        "outputId": "a1ef9b2d-5571-4208-88c1-e39a8d65302b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfbba861"
      },
      "source": [
        "import matplotlib.pyplot as plt # Import matplotlib here for SHAP plots"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3755569",
        "outputId": "87ae41ef-8817-4047-fd15-a8ef34c27b56",
        "collapsed": true
      },
      "source": [
        "%pip install streamlit"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.47.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.48.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e12f96a6",
        "outputId": "94d313d3-5ceb-434a-b822-5d1f1b8eb8b6",
        "collapsed": true
      },
      "source": [
        "%pip install lime"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lime in /usr/local/lib/python3.11/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lime) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lime) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from lime) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.11/dist-packages (from lime) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52d3efd9",
        "outputId": "928ed3c4-2104-428a-d3d9-1ec988848cd1"
      },
      "source": [
        "import os\n",
        "\n",
        "datasets_path = '/content/drive/MyDrive/Datasets/'\n",
        "if os.path.exists(datasets_path):\n",
        "    print(f\"Contents of {datasets_path}:\")\n",
        "    for filename in os.listdir(datasets_path):\n",
        "        print(os.path.join(datasets_path, filename))\n",
        "else:\n",
        "    print(f\"Directory not found: {datasets_path}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of /content/drive/MyDrive/Datasets/:\n",
            "/content/drive/MyDrive/Datasets/merged_all_features_final.csv\n",
            "/content/drive/MyDrive/Datasets/.ipynb_checkpoints\n",
            "/content/drive/MyDrive/Datasets/X_train_processed_ensemble.csv\n",
            "/content/drive/MyDrive/Datasets/y_train_imputed.csv\n",
            "/content/drive/MyDrive/Datasets/y_train_processed_ensemble.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a776e95a",
        "outputId": "786e6266-f63e-4b5b-9a21-e1bef19b01b7"
      },
      "source": [
        "import os\n",
        "\n",
        "# Creating the 'pages' directory if it doesn't exist\n",
        "pages_dir = \"pages\"\n",
        "os.makedirs(pages_dir, exist_ok=True)\n",
        "print(f\"Created directory: {pages_dir}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created directory: pages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9b6952c",
        "outputId": "e9ef31bf-92db-410a-ea47-0c7355db325b"
      },
      "source": [
        "%%writefile app.py\n",
        "# -*- coding: utf-8 -*-\n",
        "import streamlit as st\n",
        "import os\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"Global Pay Insight\",\n",
        "    page_icon=\"🌍\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "st.sidebar.title(\"Navigation\")\n",
        "\n",
        "st.title(\"🌍 Global Pay Insight\")\n",
        "st.markdown(\"\"\"\n",
        "Welcome to Global Pay Insight! This application helps you predict your potential salary based on a comprehensive dataset and explore insights into global pay trends and potential disparities.\n",
        "\n",
        "Use the navigation on the left to:\n",
        "- **Predict Your Salary**: Get a personalized salary estimate and understand the key factors influencing it.\n",
        "- **Explore Pay Gaps & Trends**: Visualize salary averages across different demographics and professional categories.\n",
        "- **About Our Model**: Learn about the machine learning model powering this application, its data sources, and limitations.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "st.info(\"Please note: This application is for informational purposes based on available data and models. Actual salaries can vary widely due to many factors not included here.\")\n",
        "\n",
        "# Ensuring required directories exist if needed by page scripts (though pages should handle their own needs)\n",
        "# os.makedirs('/content/drive/MyDrive/saved_models', exist_ok=True)\n",
        "# os.makedirs('/content/drive/MyDrive/Datasets', exist_ok=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f21ea12",
        "outputId": "c2cae8ae-2535-4552-bde6-47eaf0ea54a6"
      },
      "source": [
        "%%writefile pages/1_Predict_Your_Salary.py\n",
        "# -*- coding: utf-8 -*-\n",
        "import streamlit as st\n",
        "import joblib\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "import re\n",
        "\n",
        "\n",
        "st.set_page_config(page_title=\"Predict Your Salary\", page_icon=\"💰\", layout=\"wide\")\n",
        "\n",
        "# --- Configuration and Data Loading ---\n",
        "MODEL_PATH = '/content/drive/MyDrive/saved_models/voting_regressor_ensemble.joblib'\n",
        "FACTORS_PATH = '/content/drive/MyDrive/saved_models/adjustment_factors.joblib'\n",
        "TRAIN_DATA_PATH = '/content/drive/MyDrive/Datasets/X_train_processed_ensemble.csv'\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model(path):\n",
        "    try:\n",
        "        model = joblib.load(path)\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading model from {path}: {e}\")\n",
        "        return None\n",
        "\n",
        "@st.cache_resource\n",
        "def load_adjustment_factors(path):\n",
        "    try:\n",
        "        factors = joblib.load(path)\n",
        "        return factors\n",
        "    except Exception as e:\n",
        "        st.warning(f\"Could not load fairness adjustment factors from {path}: {e}\")\n",
        "        return None\n",
        "\n",
        "@st.cache_resource\n",
        "def load_processed_training_data(path):\n",
        "    if os.path.exists(path):\n",
        "        try:\n",
        "            # Load the DataFrame, handle potential 'Unnamed: 0' if it exists\n",
        "            df = pd.read_csv(path)\n",
        "            if 'Unnamed: 0' in df.columns:\n",
        "                df = df.drop(columns=['Unnamed: 0'])\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error loading processed training data from {path}: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        st.error(f\"Processed training data not found at {path}\")\n",
        "        return None\n",
        "\n",
        "# Loading all components\n",
        "voting_regressor = load_model(MODEL_PATH)\n",
        "adjustment_factors_by_sensitive_attribute = load_adjustment_factors(FACTORS_PATH)\n",
        "X_train_processed_ensemble = load_processed_training_data(TRAIN_DATA_PATH)\n",
        "\n",
        "# This is the critical line: model_features should contain all columns from the CSV\n",
        "model_features = X_train_processed_ensemble.columns.tolist() if X_train_processed_ensemble is not None else []\n",
        "\n",
        "\n",
        "if voting_regressor is None or not model_features:\n",
        "    st.error(\"Essential components could not be loaded. Please check file paths and ensure the model and data are correctly formatted.\")\n",
        "    st.stop()\n",
        "\n",
        "# Defining PCA NLP feature importance order based on your provided columns\n",
        "pca_nlp_importance_order = [f'pca_nlp_{i}' for i in range(15)]\n",
        "\n",
        "# Filtering to only include pca_nlp features that are actually in the model features\n",
        "pca_nlp_features_ordered = [f for f in pca_nlp_importance_order if f in model_features]\n",
        "\n",
        "# Defining generic labels for PCA NLP features\n",
        "generic_nlp_labels = [\n",
        "    \"Job Complexity Factor 1\", \"Role Scope Dimension\", \"Skill Specialization Score\",\n",
        "    \"Duties Component (Main)\", \"Tasks Component (Secondary)\", \"Text Pattern 1\",\n",
        "    \"Job Description Feature (PCA-7)\", \"Text Pattern 2\", \"Job Description Feature (PCA-9)\",\n",
        "    \"Text Pattern 3\", \"Job Description Feature (PCA-11)\", \"Job Complexity Factor 2\",\n",
        "    \"Text Pattern 4\", \"Skill Specialization Score 2\", \"Duties Component (Secondary)\",\n",
        "]\n",
        "# Creating a dictionary to map pca_nlp names to generic labels\n",
        "nlp_label_map = {pca_col: generic_nlp_labels[i] for i, pca_col in enumerate(pca_nlp_features_ordered) if i < len(generic_nlp_labels)}\n",
        "\n",
        "\n",
        "def get_imputer(train_data):\n",
        "    \"\"\"Creates and fits a median imputer on the training data.\"\"\"\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    # Fitting only on numerical columns to avoid errors with object/boolean types\n",
        "    numerical_cols = train_data.select_dtypes(include=np.number).columns\n",
        "    imputer.fit(train_data[numerical_cols])\n",
        "    return imputer, numerical_cols\n",
        "\n",
        "imputer_for_predict_fn, numerical_features_for_imputation = get_imputer(X_train_processed_ensemble)\n",
        "\n",
        "\n",
        "def clean_feature_name(feature_name):\n",
        "    \"\"\"Clean feature names for display\"\"\"\n",
        "    # Handling boolean features like Gender_Female, Gender_Male\n",
        "    if feature_name.startswith(('Gender_', 'Country_', 'continent_name_',\n",
        "                                'ManageStaff_', 'EducationIsComputerRelated_',\n",
        "                                'EmploymentSector_', 'LookingForAnotherJob_',\n",
        "                                'CareerPlansThisYear_', 'JobTitle_', 'EmploymentStatus_')):\n",
        "        # Removing prefix and replace underscores with spaces, then title case\n",
        "        parts = feature_name.split('_', 1) # Split only on the first underscore\n",
        "        if len(parts) > 1:\n",
        "             cleaned = parts[1].replace('_', ' ').title()\n",
        "             # Handling specific cases like '1__this_is...'\n",
        "             cleaned = cleaned.replace('  This Is The Only Company Where I Ve Had This Kind Of Position ', ' (1st Company in this Role)')\n",
        "        else:\n",
        "             cleaned = feature_name.replace('_', ' ').title() # Fallback if no underscore after prefix\n",
        "        return cleaned\n",
        "    elif feature_name.startswith('pca_nlp_'):\n",
        "        # Using the generic label mapping for PCA NLP features\n",
        "        return nlp_label_map.get(feature_name, feature_name.replace('_', ' ').title())\n",
        "    else:\n",
        "        return feature_name.replace('_', ' ').title()\n",
        "\n",
        "\n",
        "def get_ohe_options(prefix, model_features):\n",
        "    \"\"\"\n",
        "    Extracts and cleans options for one-hot encoded features based on a prefix.\n",
        "    Returns a sorted list of unique options, using clean_feature_name.\n",
        "    \"\"\"\n",
        "    cols = [col for col in model_features if col.startswith(prefix)]\n",
        "\n",
        "    if not cols:\n",
        "        return []\n",
        "\n",
        "    # Applying clean_feature_name to get display options\n",
        "    options = [clean_feature_name(col) for col in cols]\n",
        "\n",
        "    # Removing duplicates and sort for consistent display\n",
        "    options = sorted(list(set(options)))\n",
        "    return options\n",
        "\n",
        "def preprocess_user_input(user_input_data, model_features, X_train_df, imputer, numerical_cols_for_imputation):\n",
        "    \"\"\"\n",
        "    Preprocesses user input to match the model's expected feature format.\n",
        "    Handles OHE features dynamically based on model_features.\n",
        "    Applies imputation to numerical features.\n",
        "    \"\"\"\n",
        "    processed_input = {feature: 0 for feature in model_features}\n",
        "\n",
        "    # Numerical features (direct mapping)\n",
        "    if 'YearsOfExperience' in user_input_data and user_input_data['YearsOfExperience'] is not None:\n",
        "        if 'YearsOfExperience' in model_features:\n",
        "            processed_input['YearsOfExperience'] = user_input_data['YearsOfExperience']\n",
        "        # Handling squared term if it exists in model features\n",
        "        if 'YearsOfExperience_sq' in model_features:\n",
        "            processed_input['YearsOfExperience_sq'] = user_input_data['YearsOfExperience']**2\n",
        "\n",
        "    # Handling 'CompanySize' (numerical mapping from friendly string)\n",
        "    company_size_mapping = {'1-5': 3, '6-99': 52.5, '100-249': 174.5, '250-499': 374.5, '500-999': 749.5, '1000 or more': 1500}\n",
        "    if 'CompanySize_friendly' in user_input_data and user_input_data['CompanySize_friendly'] is not None:\n",
        "        if 'CompanySize' in model_features: # Check if the numerical column exists\n",
        "             processed_input['CompanySize'] = company_size_mapping.get(user_input_data['CompanySize_friendly'], np.nan)\n",
        "\n",
        "\n",
        "    # Handling 'TeamSize' (direct numerical input)\n",
        "    if 'TeamSize' in user_input_data and user_input_data['TeamSize'] is not None:\n",
        "        if 'TeamSize' in model_features:\n",
        "            processed_input['TeamSize'] = user_input_data['TeamSize']\n",
        "\n",
        "    # Handling 'HasCertifications' (direct binary input, not OHE with prefix)\n",
        "    # Assuming 'HasCertifications' is a binary numerical column (0 or 1)\n",
        "    if 'HasCertifications' in user_input_data and user_input_data['HasCertifications'] is not None:\n",
        "        if 'HasCertifications' in model_features:\n",
        "            processed_input['HasCertifications'] = 1 if user_input_data['HasCertifications'] == 'Yes' else 0\n",
        "\n",
        "    # One-Hot Encoded Features (dynamic handling with CORRECTED prefixes)\n",
        "    # Mapping friendly input names to the OHE prefixes used in the model features\n",
        "    ohe_mappings = {\n",
        "        'Gender': 'Gender_',\n",
        "        'Country': 'Country_',\n",
        "        'Continent': 'continent_name_',\n",
        "        'Manages Staff': 'ManageStaff_',\n",
        "        'Is Education Computer Related?': 'EducationIsComputerRelated_',\n",
        "        'Employment Sector': 'EmploymentSector_',\n",
        "        'Are you Looking for Another Job?': 'LookingForAnotherJob_',\n",
        "        'Your Career Plans This Year': 'CareerPlansThisYear_',\n",
        "        'Your Job Title': 'JobTitle_',\n",
        "        'Employment Status': 'EmploymentStatus_'\n",
        "    }\n",
        "\n",
        "    for friendly_key, prefix in ohe_mappings.items():\n",
        "        if friendly_key in user_input_data and user_input_data[friendly_key] is not None:\n",
        "            user_value = user_input_data[friendly_key]\n",
        "            # Converting the user-friendly value back to a format that matches the original OHE column names\n",
        "            #trying to reconstruct a likely original column name.\n",
        "            # This might require adjusting based on the exact format in X_train_processed_ensemble.csv\n",
        "            original_ohe_part = user_value.replace(' (1st Company in this Role)', '_this_is_the_only_company_where_I_ve_had_this_kind_of_position_').replace(' ', '_').title()\n",
        "\n",
        "            # Handling boolean-like OHEs where the column name is just the prefix + value (e.g., Gender_Male)\n",
        "            if user_value.lower() in ['yes', 'no', 'true', 'false']: # Example boolean-like options\n",
        "                 ohe_col = f\"{prefix}{user_value.title()}\"\n",
        "            else: # Handle categorical OHEs\n",
        "                 ohe_col = f\"{prefix}{original_ohe_part}\"\n",
        "\n",
        "            # Checking if the constructed OHE column name exists in the model features\n",
        "            if ohe_col in model_features:\n",
        "                 processed_input[ohe_col] = 1\n",
        "            else:\n",
        "                 # Fallback for cases where the reconstruction doesn't match or the option is missing\n",
        "                 # This could happen if the cleaning process was complex or data is sparse.\n",
        "                 # A safer approach might be to iterate through model_features and match the cleaned name.\n",
        "                 # For now, just passing if the column isn't found.\n",
        "                 pass\n",
        "\n",
        "\n",
        "    # Processing PCA NLP features\n",
        "    for pca_col in pca_nlp_features_ordered:\n",
        "         if pca_col in user_input_data and user_input_data[pca_col] is not None:\n",
        "            processed_input[pca_col] = user_input_data[pca_col]\n",
        "\n",
        "    # Converting to DataFrame\n",
        "    user_input_df = pd.DataFrame([processed_input], columns=model_features)\n",
        "\n",
        "    # Applying imputation only to the numerical columns that were used for fitting\n",
        "    user_input_df_numerical = user_input_df[numerical_cols_for_imputation]\n",
        "    user_input_df_imputed_numerical = pd.DataFrame(\n",
        "        imputer.transform(user_input_df_numerical),\n",
        "        columns=numerical_cols_for_imputation,\n",
        "        index=user_input_df_numerical.index\n",
        "    )\n",
        "\n",
        "    # Combining imputed numerical columns with non-numerical columns (like booleans)\n",
        "    # Finding non-numerical columns in the user input dataframe\n",
        "    non_numerical_cols = user_input_df.columns.difference(numerical_cols_for_imputation)\n",
        "    user_input_df_final = pd.concat([user_input_df_imputed_numerical, user_input_df[non_numerical_cols]], axis=1)\n",
        "\n",
        "    # Ensuring the final dataframe has the same column order as model_features\n",
        "    user_input_df_final = user_input_df_final[model_features]\n",
        "\n",
        "    return user_input_df_final\n",
        "\n",
        "\n",
        "# --- Streamlit UI ---\n",
        "st.header(\"💰 Salary Prediction Tool\")\n",
        "st.markdown(\"Enter your details for a personalized salary estimate\")\n",
        "\n",
        "user_input_data = {}\n",
        "\n",
        "# Section 1: Identity and Location\n",
        "with st.container():\n",
        "    st.subheader(\"🌍 Your Identity\")\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "\n",
        "    with col1:\n",
        "        gender_options = get_ohe_options('Gender_', model_features)\n",
        "        if gender_options:\n",
        "            user_input_data['Gender'] = st.selectbox(\"Gender\", gender_options)\n",
        "        else:\n",
        "            st.warning(\"Gender options not found in model features. Please check data preprocessing.\")\n",
        "            user_input_data['Gender'] = None\n",
        "\n",
        "    with col2:\n",
        "        country_options = get_ohe_options('Country_', model_features)\n",
        "        if country_options:\n",
        "             user_input_data['Country'] = st.selectbox(\"Country\", country_options)\n",
        "        else:\n",
        "            st.warning(\"Country options not found in model features. Please check data preprocessing.\")\n",
        "            user_input_data['Country'] = None\n",
        "\n",
        "    with col3:\n",
        "        continent_options = get_ohe_options('continent_name_', model_features)\n",
        "        if continent_options:\n",
        "            user_input_data['Continent'] = st.selectbox(\"Continent\", continent_options) # Use friendly name 'Continent'\n",
        "        else:\n",
        "            st.warning(\"Continent options not found in model features. Please check data preprocessing.\")\n",
        "            user_input_data['Continent'] = None\n",
        "\n",
        "# Section 2: Professional Details\n",
        "with st.container():\n",
        "    st.subheader(\"💼 Professional Information\")\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        # Checking if 'YearsOfExperience' is a numerical column in the training data for min/max\n",
        "        if 'YearsOfExperience' in X_train_processed_ensemble.select_dtypes(include=np.number).columns:\n",
        "            min_years = float(X_train_processed_ensemble['YearsOfExperience'].min()) if not np.isnan(X_train_processed_ensemble['YearsOfExperience'].min()) else 0.0\n",
        "            max_years = float(X_train_processed_ensemble['YearsOfExperience'].max()) if not np.isnan(X_train_processed_ensemble['YearsOfExperience'].max()) else 50.0\n",
        "            user_input_data['YearsOfExperience'] = st.number_input(\n",
        "                \"Years in Role\",\n",
        "                min_value=min_years,\n",
        "                max_value=max_years,\n",
        "                value=min(5.0, max_years),\n",
        "                step=0.1 # Allow for fractional years\n",
        "            )\n",
        "        else:\n",
        "            st.warning(\"YearsOfExperience column not found or is not numerical in training data. Defaulting to a generic input.\")\n",
        "            user_input_data['YearsOfExperience'] = st.number_input(\"Years in Role\", min_value=0.0, max_value=50.0, value=5.0, step=0.1)\n",
        "\n",
        "\n",
        "        company_size_mapping = {\n",
        "            '1-5': 3, '6-99': 52.5, '100-249': 174.5,\n",
        "            '250-499': 374.5, '500-999': 749.5, '1000 or more': 1500\n",
        "        }\n",
        "        # Checking if the numerical 'CompanySize' column exists for model input\n",
        "        if 'CompanySize' in model_features:\n",
        "            user_input_data['CompanySize_friendly'] = st.selectbox( # Use friendly name for UI\n",
        "                \"Company Size\",\n",
        "                options=list(company_size_mapping.keys())\n",
        "            )\n",
        "        else:\n",
        "            st.warning(\"CompanySize column not found in model features. Cannot select company size.\")\n",
        "            user_input_data['CompanySize_friendly'] = None\n",
        "\n",
        "        # Checking if 'TeamSize' is a numerical column in the training data for min/max\n",
        "        if 'TeamSize' in X_train_processed_ensemble.select_dtypes(include=np.number).columns:\n",
        "            min_team_size = int(X_train_processed_ensemble['TeamSize'].min()) if not np.isnan(X_train_processed_ensemble['TeamSize'].min()) else 0\n",
        "            max_team_size = int(X_train_processed_ensemble['TeamSize'].max()) if not np.isnan(X_train_processed_ensemble['TeamSize'].max()) else 1000\n",
        "            user_input_data['TeamSize'] = st.number_input(\"Team Size\", min_value=min_team_size, max_value=max_team_size, value=min(10, max_team_size), step=1)\n",
        "        else:\n",
        "            st.warning(\"TeamSize column not found or is not numerical in training data. Cannot select team size.\")\n",
        "            user_input_data['TeamSize'] = None\n",
        "\n",
        "\n",
        "    with col2:\n",
        "        managestaff_options = get_ohe_options('ManageStaff_', model_features)\n",
        "        if managestaff_options:\n",
        "            user_input_data['Manages Staff'] = st.selectbox(\"Manages Staff\", managestaff_options) # Use friendly name\n",
        "        else:\n",
        "            st.warning(\"Manage Staff options not found in model features. Please check data preprocessing.\")\n",
        "            user_input_data['Manages Staff'] = None\n",
        "\n",
        "        # Check if 'HasCertifications' is a numerical column for model input\n",
        "        if 'HasCertifications' in model_features:\n",
        "            user_input_data['HasCertifications'] = st.selectbox(\"Has Certifications\", options=['Yes', 'No'])\n",
        "        else:\n",
        "            st.warning(\"HasCertifications column not found in model features. Cannot select certifications.\")\n",
        "            user_input_data['HasCertifications'] = None\n",
        "\n",
        "# Section 3: Additional Features\n",
        "with st.container():\n",
        "    st.subheader(\"📝 Additional Information\")\n",
        "\n",
        "    education_options = get_ohe_options('EducationIsComputerRelated_', model_features)\n",
        "    if education_options:\n",
        "        user_input_data['Is Education Computer Related?'] = st.selectbox(\"Is Education Computer Related?\", education_options) # Use friendly name\n",
        "    else:\n",
        "        st.warning(\"EducationIsComputerRelated options not found in model features. Please check data preprocessing.\")\n",
        "        user_input_data['Is Education Computer Related?'] = None\n",
        "\n",
        "    employment_sector_options = get_ohe_options('EmploymentSector_', model_features)\n",
        "    if employment_sector_options:\n",
        "        user_input_data['Employment Sector'] = st.selectbox(\"Employment Sector\", employment_sector_options) # Use friendly name\n",
        "    else:\n",
        "        st.warning(\"Employment Sector options not found in model features. Please check data preprocessing.\")\n",
        "        user_input_data['Employment Sector'] = None\n",
        "\n",
        "    # Assuming 'EmploymentStatus' is also one-hot encoded\n",
        "    employment_status_options = get_ohe_options('EmploymentStatus_', model_features)\n",
        "    if employment_status_options:\n",
        "        user_input_data['Employment Status'] = st.selectbox(\"Employment Status\", employment_status_options) # Use friendly name\n",
        "    else:\n",
        "        st.warning(\"Employment Status options not found in model features. Please check data preprocessing.\")\n",
        "        user_input_data['Employment Status'] = None\n",
        "\n",
        "\n",
        "    job_title_options = get_ohe_options('JobTitle_', model_features)\n",
        "    if job_title_options:\n",
        "        user_input_data['Your Job Title'] = st.selectbox(\"Your Job Title\", job_title_options) # Use friendly name\n",
        "    else:\n",
        "        st.warning(\"Job Title options not found in model features. Please check data preprocessing.\")\n",
        "        user_input_data['Your Job Title'] = None\n",
        "\n",
        "\n",
        "# Career Outlook\n",
        "with st.container():\n",
        "    st.subheader(\"🎯 Career Outlook\")\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        looking_for_another_job_options = get_ohe_options('LookingForAnotherJob_', model_features)\n",
        "        if looking_for_another_job_options:\n",
        "            user_input_data['Are you Looking for Another Job?'] = st.selectbox(\"Are you Looking for Another Job?\", looking_for_another_job_options) # Use friendly name\n",
        "        else:\n",
        "            st.warning(\"Looking For Another Job options not found in model features. Please check data preprocessing.\")\n",
        "            user_input_data['Are you Looking for Another Job?'] = None\n",
        "\n",
        "    with col2:\n",
        "        career_plans_options = get_ohe_options('CareerPlansThisYear_', model_features)\n",
        "        if career_plans_options:\n",
        "            user_input_data['Your Career Plans This Year'] = st.selectbox(\"Your Career Plans This Year\", career_plans_options) # Use friendly name\n",
        "        else:\n",
        "            st.warning(\"Career Plans This Year options not found in model features. Please check data preprocessing.\")\n",
        "            user_input_data['Your Career Plans This Year'] = None\n",
        "\n",
        "# Text areas for NLP features (these don't directly map to OHEs, but their PCA components do)\n",
        "# Text input is for user experience, but the model uses PCA features derived from text.\n",
        "# Adding placeholder text areas here but won't use them directly in the prediction for now,as don't have a live NLP processing step in this app. The user can adjust the PCA sliders below.\n",
        "with st.container():\n",
        "    st.subheader(\"📝 Job Responsibilities & Tasks (For Context - Adjust Sliders Below)\")\n",
        "    st.write(\"Provide text descriptions for context, but adjust the sliders below to directly influence the NLP-derived factors used in the model.\")\n",
        "    st.text_area(\n",
        "        \"Describe Your Job Responsibilities & Tasks\",\n",
        "        help=\"This text area is for your reference and does not directly feed into the current prediction model in this demo. Adjust the 'Advanced Text-Derived Factors' sliders below.\",\n",
        "        key='other_job_duties_text_area'\n",
        "    )\n",
        "    st.text_area(\n",
        "        \"Describe the Kinds of Tasks You Perform\",\n",
        "        help=\"This text area is for your reference and does not directly feed into the current prediction model in this demo. Adjust the 'Advanced Text-Derived Factors' sliders below.\",\n",
        "        key='kinds_of_tasks_performed_text_area'\n",
        "    )\n",
        "\n",
        "\n",
        "# Sliders for Advanced Text-Derived Factors (PCA NLP features)\n",
        "st.subheader(\"✨ Advanced Text-Derived Factors\")\n",
        "st.info(\"These factors are automatically generated from text descriptions of job duties and tasks provided in the original data. While not directly interpretable, they capture nuances that influence salary. Adjust them to see their hypothetical impact.\")\n",
        "\n",
        "col_nlp_count = 5 # Number of columns for sliders\n",
        "nlp_cols = st.columns(col_nlp_count)\n",
        "for i, pca_col in enumerate(pca_nlp_features_ordered):\n",
        "    if pca_col in model_features:\n",
        "        # Ensureing min/max/mean are calculated only on numerical columns\n",
        "        if pca_col in X_train_processed_ensemble.select_dtypes(include=np.number).columns:\n",
        "            min_val = float(X_train_processed_ensemble[pca_col].min()) if not np.isnan(X_train_processed_ensemble[pca_col].min()) else 0.0\n",
        "            max_val = float(X_train_processed_ensemble[pca_col].max()) if not np.isnan(X_train_processed_ensemble[pca_col].max()) else 1.0\n",
        "            mean_val = float(X_train_processed_ensemble[pca_col].mean()) if not np.isnan(X_train_processed_ensemble[pca_col].mean()) else 0.0\n",
        "        else:\n",
        "             # Default values if the column is not numerical or has no variation\n",
        "             min_val, max_val, mean_val = 0.0, 1.0, 0.0\n",
        "             st.warning(f\"PCA NLP feature '{pca_col}' not found or is not numerical in training data. Defaulting slider range.\")\n",
        "\n",
        "\n",
        "        with nlp_cols[i % col_nlp_count]:\n",
        "            # Using the generic label if available, otherwise fallback\n",
        "            label_to_display = nlp_label_map.get(pca_col, f\"Text Factor {i + 1}\")\n",
        "            # Adding a unique key for each slider\n",
        "            user_input_data[pca_col] = st.slider(label_to_display, min_val, max_val, mean_val, key=f'nlp_slider_{pca_col}', help=\"This slider represents an abstract factor derived from job descriptions and tasks. Adjust it to see its hypothetical impact on salary.\")\n",
        "\n",
        "st.markdown(\"---\")\n",
        "\n",
        "apply_adjustment = st.checkbox(\"Apply Fairness Adjustment (based on Gender)\", value=True, help=\"Applying this adjustment may modify the prediction to help mitigate potential bias related to gender, based on patterns observed in the training data.\")\n",
        "\n",
        "# --- Prediction Button ---\n",
        "if st.button(\"Predict Salary\"):\n",
        "    with st.spinner(\"Calculating...\"):\n",
        "        # Ensuring all necessary keys are in user_input_data, even if None, so preprocess_user_input doesn't fail on missing keys.\n",
        "        # This could be done more robustly by checking against expected keys from UI elements.\n",
        "        # For now, relying on preprocess_user_input handling missing keys gracefully.\n",
        "\n",
        "        user_input_df = preprocess_user_input(user_input_data, model_features, X_train_processed_ensemble, imputer_for_predict_fn, numerical_features_for_imputation)\n",
        "\n",
        "        try:\n",
        "            raw_prediction = voting_regressor.predict(user_input_df)[0]\n",
        "\n",
        "            st.subheader(\"Results\")\n",
        "            st.success(f\"Predicted Salary: ${raw_prediction:,.2f}\")\n",
        "\n",
        "            # Fairness adjustment\n",
        "            if apply_adjustment and adjustment_factors_by_sensitive_attribute:\n",
        "                # Getting the user's selected gender (cleaned name)\n",
        "                selected_gender_cleaned = user_input_data.get('Gender')\n",
        "\n",
        "                # Finding the original gender column name that corresponds to the selected cleaned name\n",
        "                original_gender_col = None\n",
        "                if selected_gender_cleaned:\n",
        "                    # Iteratng through the original gender columns to find a match\n",
        "                    for col in model_features:\n",
        "                        if col.startswith('Gender_') and clean_feature_name(col) == selected_gender_cleaned:\n",
        "                            original_gender_col = col\n",
        "                            break\n",
        "\n",
        "                if original_gender_col and original_gender_col in adjustment_factors_by_sensitive_attribute:\n",
        "                    adjustment = adjustment_factors_by_sensitive_attribute[original_gender_col]\n",
        "                    adjusted_prediction = raw_prediction + adjustment\n",
        "                    st.info(f\"Fairness Adjusted Salary: ${adjusted_prediction:,.2f}\")\n",
        "                else:\n",
        "                    st.warning(f\"Adjustment factors for selected gender '{selected_gender_cleaned}' not found. No fairness adjustment applied.\")\n",
        "            elif apply_adjustment and not adjustment_factors_by_sensitive_attribute:\n",
        "                 st.warning(\"Fairness adjustment factors could not be loaded. No adjustment applied.\")\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"An error occurred during prediction: {e}\")\n",
        "            st.error(\"Please check the input values and ensure the model and data are correctly loaded.\")\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.caption(\"Note: This is a predictive estimate based on available data\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting pages/1_Predict_Your_Salary.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feea66f3",
        "outputId": "81df181b-f7ea-4b10-9306-58d1de6b8764"
      },
      "source": [
        "%%writefile pages/2_Explore_Pay_Gaps_&_Trends.py\n",
        "# -*- coding: utf-8 -*-\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import os\n",
        "import re\n",
        "\n",
        "st.header(\"Explore Pay Gaps & Trends 📊\")\n",
        "st.markdown(\"Visualize salary trends and potential pay gaps based on the dataset.\")\n",
        "\n",
        "# Loading processed training data and salary data\n",
        "TRAIN_DATA_PATH = '/content/drive/MyDrive/Datasets/X_train_processed_ensemble.csv'\n",
        "SALARY_DATA_PATH = '/content/drive/MyDrive/Datasets/y_train_processed_ensemble.csv'\n",
        "\n",
        "# Adding a button to clear the cache\n",
        "if st.button(\"Clear Cache and Reload Data\"):\n",
        "    st.cache_data.clear()\n",
        "    st.rerun()\n",
        "\n",
        "@st.cache_data\n",
        "def load_and_prepare_data(train_path, salary_path):\n",
        "    \"\"\"Loads and prepares the data for visualization.\"\"\"\n",
        "    if not os.path.exists(train_path):\n",
        "        st.error(f\"Training data file not found at: {train_path}\")\n",
        "        return None\n",
        "    if not os.path.exists(salary_path):\n",
        "        st.error(f\"Salary data file not found at: {salary_path}\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        df_train = pd.read_csv(train_path)\n",
        "        # Dropping 'Unnamed: 0' if it exists and reset index for reliable concatenation\n",
        "        if 'Unnamed: 0' in df_train.columns:\n",
        "            df_train = df_train.drop(columns=['Unnamed: 0'])\n",
        "        df_train = df_train.reset_index(drop=True)\n",
        "\n",
        "        df_salary = pd.read_csv(salary_path)\n",
        "        # Dropping 'Unnamed: 0' if it exists and reset index for reliable concatenation\n",
        "        if 'Unnamed: 0' in df_salary.columns:\n",
        "            df_salary = df_salary.drop(columns=['Unnamed: 0'])\n",
        "        df_salary = df_salary.reset_index(drop=True)\n",
        "\n",
        "        # Checking if both dataframes have the same number of rows. If not, truncate to the minimum.\n",
        "        if df_train.shape[0] != df_salary.shape[0]:\n",
        "            min_rows = min(df_train.shape[0], df_salary.shape[0])\n",
        "            # Removed the st.warning here\n",
        "            df_train = df_train.iloc[:min_rows].reset_index(drop=True)\n",
        "            df_salary = df_salary.iloc[:min_rows].reset_index(drop=True)\n",
        "\n",
        "\n",
        "        # Concatenating the dataframes. Assuming they are aligned by index after reset/truncation.\n",
        "        df = pd.concat([df_train, df_salary], axis=1)\n",
        "\n",
        "        # Cleaning column names for consistency\n",
        "        df.columns = [\"\".join(c if re.fullmatch(r'[A-Za-z0-9_]+', c) else '_' for c in str(x)) for x in df.columns]\n",
        "        df = df.loc[:, ~df.columns.duplicated(keep='first')] # Drop duplicates if any\n",
        "\n",
        "        # Renaming the salary column to a consistent name if it exists\n",
        "        salary_col = None\n",
        "        for col in df.columns:\n",
        "            if 'salary' in col.lower() and 'usd' in col.lower():\n",
        "                salary_col = col\n",
        "                break\n",
        "\n",
        "        if salary_col is None:\n",
        "            st.error(\"Could not find a column containing 'salary' and 'usd'. Please ensure the salary column exists and is named appropriately.\")\n",
        "            return None\n",
        "\n",
        "        df = df.rename(columns={salary_col: 'salaryusd'})\n",
        "\n",
        "\n",
        "        # Dropping rows with missing salary values\n",
        "        df = df.dropna(subset=['salaryusd'])\n",
        "\n",
        "        # Data Cleaning and Preparation for Visualization\n",
        "        def clean_col_name_for_display(col_name):\n",
        "            \"\"\"Clean feature names for display in plots.\"\"\"\n",
        "            cleaned = col_name.replace('_', ' ').title()\n",
        "            # Specific replacements for common patterns\n",
        "            cleaned = cleaned.replace('Pca Nlp ', 'Text Factor ')\n",
        "            cleaned = cleaned.replace('Continent Name ', 'Continent ')\n",
        "            cleaned = cleaned.replace('Managestaff ', 'Manages Staff ')\n",
        "            cleaned = cleaned.replace('Educationiscomputerrelated ', 'Education Computer Related ')\n",
        "            cleaned = cleaned.replace('Employmentsector ', 'Employment Sector ')\n",
        "            cleaned = cleaned.replace('Lookingforanotherjob ', 'Looking For Another Job ')\n",
        "            cleaned = cleaned.replace('Careerplansthisyear ', 'Career Plans This Year ')\n",
        "            cleaned = cleaned.replace('Jobtitle ', 'Job Title ')\n",
        "            cleaned = cleaned.replace('1  This Is The Only Company Where I Ve Had This Kind Of Position ', ' (1st Company in this Role)')\n",
        "\n",
        "            return cleaned.strip() # Remove leading/trailing spaces\n",
        "\n",
        "        # Identifying and cleaning relevant columns for plotting\n",
        "        plot_df = pd.DataFrame(index=df.index)\n",
        "        plot_df['salaryusd'] = df['salaryusd']\n",
        "\n",
        "        # Gender\n",
        "        gender_cols = [col for col in df.columns if col.startswith('gender_')]\n",
        "        if gender_cols:\n",
        "            # Use idxmax to get the column name with the max value (which should be 1 for the selected category)\n",
        "            plot_df['Gender'] = df[gender_cols].idxmax(axis=1).apply(lambda x: clean_col_name_for_display(x.replace('gender_', '')))\n",
        "        else:\n",
        "            plot_df['Gender'] = 'Unknown' # Default if no gender columns\n",
        "\n",
        "        # Country (Top N for visualization)\n",
        "        country_cols = [col for col in df.columns if col.startswith('country_')]\n",
        "        if country_cols:\n",
        "            plot_df['Country'] = df[country_cols].idxmax(axis=1).apply(lambda x: clean_col_name_for_display(x.replace('country_', '')))\n",
        "            top_countries = plot_df['Country'].value_counts().nlargest(10).index.tolist()\n",
        "            plot_df['Country_Plot'] = plot_df['Country'].apply(lambda x: x if x in top_countries else 'Other')\n",
        "        else:\n",
        "            plot_df['Country_Plot'] = 'Unknown'\n",
        "\n",
        "        # Continent\n",
        "        continent_cols = [col for col in df.columns if col.startswith('continent_name_')]\n",
        "        if continent_cols:\n",
        "            plot_df['Continent'] = df[continent_cols].idxmax(axis=1).apply(lambda x: clean_col_name_for_display(x.replace('continent_name_', '')))\n",
        "        else:\n",
        "            plot_df['Continent'] = 'Unknown'\n",
        "\n",
        "        # Years of Experience (using the numeric column)\n",
        "        if 'YearsOfExperience' in df.columns:\n",
        "            plot_df['Years_Experience'] = df['YearsOfExperience']\n",
        "        else:\n",
        "            plot_df['Years_Experience'] = 0 # Default if not available\n",
        "\n",
        "\n",
        "        # Job Title (Top N for visualization)\n",
        "        job_title_cols = [col for col in df.columns if col.startswith('jobtitle_')]\n",
        "        if job_title_cols:\n",
        "            plot_df['JobTitle'] = df[job_title_cols].idxmax(axis=1).apply(lambda x: clean_col_name_for_display(x.replace('jobtitle_', '')))\n",
        "            top_job_titles = plot_df['JobTitle'].value_counts().nlargest(10).index.tolist()\n",
        "            plot_df['JobTitle_Plot'] = plot_df['JobTitle'].apply(lambda x: x if x in top_job_titles else 'Other')\n",
        "        else:\n",
        "            plot_df['JobTitle_Plot'] = 'Unknown'\n",
        "\n",
        "        # Employment Status (assuming OHE with 'employmentstatus_' prefix or similar)\n",
        "        employment_status_cols = [col for col in df.columns if col.startswith('employmentstatus_')]\n",
        "        if employment_status_cols:\n",
        "            plot_df['EmploymentStatus'] = df[employment_status_cols].idxmax(axis=1).apply(lambda x: clean_col_name_for_display(x.replace('employmentstatus_', '')))\n",
        "        else:\n",
        "            plot_df['EmploymentStatus'] = 'Unknown'\n",
        "\n",
        "        # Employment Sector (assuming OHE with 'employmentsector_' prefix or similar)\n",
        "        employment_sector_cols = [col for col in df.columns if col.startswith('employmentsector_')]\n",
        "        if employment_sector_cols:\n",
        "            plot_df['EmploymentSector'] = df[employment_sector_cols].idxmax(axis=1).apply(lambda x: clean_col_name_for_display(x.replace('employmentsector_', '')))\n",
        "        else:\n",
        "            plot_df['EmploymentSector'] = 'Unknown'\n",
        "\n",
        "\n",
        "        return plot_df\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"An error occurred during data loading and preparation: {e}\")\n",
        "        return None\n",
        "\n",
        "df_explore = load_and_prepare_data(TRAIN_DATA_PATH, SALARY_DATA_PATH)\n",
        "\n",
        "if df_explore is None:\n",
        "    st.stop()\n",
        "\n",
        "# --- Visualizations ---\n",
        "\n",
        "st.subheader(\"Average Salary by Gender\")\n",
        "if 'Gender' in df_explore.columns and not df_explore['Gender'].empty:\n",
        "    avg_salary_gender = df_explore.groupby('Gender')['salaryusd'].mean().reset_index()\n",
        "    if not avg_salary_gender.empty:\n",
        "        fig_gender = px.bar(avg_salary_gender, x='Gender', y='salaryusd',\n",
        "                            labels={'Gender': 'Gender', 'salaryusd': 'Average Salary (USD)'},\n",
        "                            title='Average Salary by Gender')\n",
        "        st.plotly_chart(fig_gender)\n",
        "    else:\n",
        "        st.warning(\"No gender data available for plotting.\")\n",
        "else:\n",
        "    st.warning(\"Gender column not found or is empty after data preparation.\")\n",
        "\n",
        "\n",
        "st.subheader(\"Average Salary by Top 10 Countries\")\n",
        "if 'Country_Plot' in df_explore.columns and not df_explore['Country_Plot'].empty:\n",
        "    avg_salary_country = df_explore[df_explore['Country_Plot'] != 'Other'].groupby('Country_Plot')['salaryusd'].mean().reset_index()\n",
        "    if not avg_salary_country.empty:\n",
        "        fig_country = px.bar(avg_salary_country, x='Country_Plot', y='salaryusd',\n",
        "                             labels={'Country_Plot': 'Country', 'salaryusd': 'Average Salary (USD)'},\n",
        "                             title='Average Salary by Top 10 Countries')\n",
        "        st.plotly_chart(fig_country)\n",
        "    else:\n",
        "        st.warning(\"No data available for top countries.\")\n",
        "else:\n",
        "    st.warning(\"Country_Plot column not found or is empty after data preparation.\")\n",
        "\n",
        "\n",
        "st.subheader(\"Average Salary by Continent\")\n",
        "if 'Continent' in df_explore.columns and not df_explore['Continent'].empty:\n",
        "    avg_salary_continent = df_explore.groupby('Continent')['salaryusd'].mean().reset_index()\n",
        "    if not avg_salary_continent.empty:\n",
        "        fig_continent = px.bar(avg_salary_continent, x='Continent', y='salaryusd',\n",
        "                               labels={'Continent': 'Continent', 'salaryusd': 'Average Salary (USD)'},\n",
        "                               title='Average Salary by Continent')\n",
        "        st.plotly_chart(fig_continent)\n",
        "    else:\n",
        "         st.warning(\"No data available for continents.\")\n",
        "else:\n",
        "    st.warning(\"Continent column not found or is empty after data preparation.\")\n",
        "\n",
        "st.subheader(\"Salary vs. Years of Experience\")\n",
        "if 'Years_Experience' in df_explore.columns and not df_explore['Years_Experience'].empty:\n",
        "    fig_experience = px.scatter(df_explore, x='Years_Experience', y='salaryusd',\n",
        "                                labels={'Years_Experience': 'Years in This Job Type', 'salaryusd': 'Salary (USD)'},\n",
        "                                title='Salary vs. Years of Experience',\n",
        "                                hover_data=['JobTitle_Plot', 'Country_Plot'])\n",
        "    st.plotly_chart(fig_experience)\n",
        "else:\n",
        "    st.warning(\"Years of Experience data not available for visualization.\")\n",
        "\n",
        "st.subheader(\"Average Salary by Highest Education Level\")\n",
        "if 'Education' in df_explore.columns and not df_explore['Education'].empty:\n",
        "    # Ensuring the order is maintained for plotting\n",
        "    avg_salary_education = df_explore.groupby('Education')['salaryusd'].mean().reset_index()\n",
        "    # Reindexing to ensure all categories are present and in order, filling missing with NaN (will be skipped by plot)\n",
        "    if 'Education' in df_explore.columns and pd.api.types.is_categorical_dtype(df_explore['Education']):\n",
        "         avg_salary_education = avg_salary_education.set_index('Education').reindex(df_explore['Education'].cat.categories).reset_index()\n",
        "\n",
        "    if not avg_salary_education.empty:\n",
        "        fig_education = px.bar(avg_salary_education, x='Education', y='salaryusd',\n",
        "                               labels={'Education': 'Highest Education Level', 'salaryusd': 'Average Salary (USD)'},\n",
        "                               title='Average Salary by Highest Education Level')\n",
        "        st.plotly_chart(fig_education)\n",
        "    else:\n",
        "        st.warning(\"No data available for education levels.\")\n",
        "else:\n",
        "    st.warning(\"Education column not found or is empty after data preparation.\")\n",
        "\n",
        "\n",
        "st.subheader(\"Average Salary by Employment Status\")\n",
        "if 'EmploymentStatus' in df_explore.columns and not df_explore['EmploymentStatus'].empty:\n",
        "    avg_salary_employment_status = df_explore.groupby('EmploymentStatus')['salaryusd'].mean().reset_index()\n",
        "    if not avg_salary_employment_status.empty:\n",
        "        fig_employment_status = px.bar(avg_salary_employment_status, x='EmploymentStatus', y='salaryusd',\n",
        "                                       labels={'EmploymentStatus': 'Employment Status', 'salaryusd': 'Average Salary (USD)'},\n",
        "                                       title='Average Salary by Employment Status')\n",
        "        st.plotly_chart(fig_employment_status)\n",
        "    else:\n",
        "        st.warning(\"No data available for employment status.\")\n",
        "else:\n",
        "    st.warning(\"EmploymentStatus column not found or is empty after data preparation.\")\n",
        "\n",
        "st.subheader(\"Average Salary by Employment Sector\")\n",
        "if 'EmploymentSector' in df_explore.columns and not df_explore['EmploymentSector'].empty:\n",
        "    avg_salary_employment_sector = df_explore.groupby('EmploymentSector')['salaryusd'].mean().reset_index()\n",
        "    if not avg_salary_employment_sector.empty:\n",
        "         fig_employment_sector = px.bar(avg_salary_employment_sector, x='EmploymentSector', y='salaryusd',\n",
        "                                        labels={'EmploymentSector': 'Employment Sector', 'salaryusd': 'Average Salary (USD)'},\n",
        "                                        title='Average Salary by Employment Sector')\n",
        "         st.plotly_chart(fig_employment_sector)\n",
        "    else:\n",
        "        st.warning(\"No data available for employment sectors.\")\n",
        "else:\n",
        "    st.warning(\"Employment Sector data not available for visualization.\")\n",
        "\n",
        "st.subheader(\"Average Salary by Top 10 Job Titles\")\n",
        "if 'JobTitle_Plot' in df_explore.columns and not df_explore['JobTitle_Plot'].empty:\n",
        "    avg_salary_job_title = df_explore[df_explore['JobTitle_Plot'] != 'Other'].groupby('JobTitle_Plot')['salaryusd'].mean().reset_index()\n",
        "    if not avg_salary_job_title.empty:\n",
        "        fig_job_title = px.bar(avg_salary_job_title, x='JobTitle_Plot', y='salaryusd',\n",
        "                               labels={'JobTitle_Plot': 'Job Title', 'salaryusd': 'Average Salary (USD)'},\n",
        "                               title='Average Salary by Top 10 Job Titles')\n",
        "        st.plotly_chart(fig_job_title)\n",
        "    else:\n",
        "        st.warning(\"No data available for top job titles.\")\n",
        "else:\n",
        "    st.warning(\"JobTitle_Plot column not found or is empty after data preparation.\")\n",
        "\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.subheader(\"Interpreting Pay Gaps\")\n",
        "st.write(\"\"\"\n",
        "The visualizations above show average salaries across different demographic and professional groups present in the dataset. Apparent differences in average salaries may indicate potential pay gaps.\n",
        "\n",
        "**Important Considerations:**\n",
        "- **Correlation vs. Causation**: These charts show correlations in the data, not necessarily direct causal relationships. Many factors influence salary.\n",
        "- **Intersectionality**: Pay gaps are often intersectional (e.g., the experience of women of color may differ from white women). These simple visualizations may not capture such complexities.\n",
        "- **Data Limitations**: The dataset's composition and potential biases can influence the observed trends.\n",
        "- **Controlling for Factors**: A rigorous analysis of pay gaps requires controlling for relevant factors (like experience, education, location, job title) to isolate the effect of sensitive attributes. Our prediction model attempts to do this, and the 'Fairness Adjustment' on the 'Predict Your Salary' page is one approach to mitigate observed disparities.\n",
        "These visualizations are intended to provide a high-level overview of trends and potential areas of concern within the dataset. For a deeper understanding and individual assessment, consider the prediction and explanation provided on the 'Predict Your Salary' page.\n",
        "\"\"\")"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting pages/2_Explore_Pay_Gaps_&_Trends.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cab369a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e549329-1a3e-41df-c634-232d549e5ed0"
      },
      "source": [
        "%%writefile pages/3_About_Our_Model.py\n",
        "# -*- coding: utf-8 -*-\n",
        "import streamlit as st\n",
        "\n",
        "st.header(\"About Our Model 🤖\")\n",
        "st.markdown(\"Learn about the methodology, data sources, and limitations of our salary prediction model.\")\n",
        "\n",
        "st.subheader(\"Methodology\")\n",
        "st.write(\"\"\"\n",
        "Our salary prediction tool is powered by a robust machine learning model. Specifically, we utilize an **ensemble method** called a **Voting Regressor**. This ensemble combines the strengths of multiple individual models to produce a more accurate and stable prediction.\n",
        "\n",
        "The base models contributing to our Voting Regressor are:\n",
        "- **Ridge Regression**: A linear model that handles multicollinearity and prevents overfitting by adding a penalty term.\n",
        "- **LightGBM Regressor**: A gradient boosting framework that uses tree-based learning algorithms. It's known for its speed and efficiency, especially on large datasets, while maintaining high accuracy.\n",
        "\n",
        "By combining these diverse models, the Voting Regressor leverages their collective intelligence, often leading to better performance than any single model alone.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "st.subheader(\"Data Sources\")\n",
        "st.write(\"\"\"\n",
        "The model is trained on a comprehensive dataset compiled from various publicly available sources, primarily:\n",
        "- **Kaggle Datasets**: We've utilized anonymized salary survey data from Kaggle, which includes a wide range of professional and demographic information.\n",
        "- **World Bank API**: Economic indicators such as GDP per capita were integrated from the World Bank to enrich the dataset with macroeconomic context.\n",
        "\n",
        "We continuously strive to update and expand our data sources to improve the model's accuracy and representativeness.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "st.subheader(\"Natural Language Processing (NLP) Features\")\n",
        "st.write(\"\"\"\n",
        "To capture the nuanced impact of job responsibilities and daily tasks on salary, our model analyzes your free-form text descriptions provided for 'OtherJobDuties' and 'KindsOfTasksPerformed'. We transform these descriptions into numerical 'text features' using techniques like **TF-IDF** (Term Frequency-Inverse Document Frequency) and **Principal Component Analysis (PCA)**.\n",
        "\n",
        "- **TF-IDF**: This technique assigns a numerical value to words based on how frequently they appear in a document relative to the entire dataset, helping to identify important terms.\n",
        "- **PCA**: After converting text to numerical representations with TF-IDF, PCA is applied. PCA is a dimensionality reduction technique that helps us identify the most significant underlying patterns and dimensions within the vast amount of text data. This allows our model to understand aspects like job complexity, leadership focus, or technical specialization, which are crucial for a more accurate salary estimate.\n",
        "\n",
        "These NLP-derived features, while not directly interpretable as individual words, capture valuable contextual information from your job description.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "st.subheader(\"Limitations\")\n",
        "st.warning(\"\"\"\n",
        "It's crucial to understand the limitations of any predictive model, including ours:\n",
        "- **Estimates, Not Guarantees**: The predictions provided are statistical estimates based on historical data. Actual job offers and salaries can vary widely due to negotiation skills, specific company policies, market demand at a given time, and other unique factors not included here.\n",
        "- **Data Reliance**: The model's accuracy is dependent on the quality, recency, and representativeness of the training data. Publicly available data may not capture all private or negotiated compensation nuances.\n",
        "- **Bias Detection and Mitigation**: While we actively work to identify and mitigate biases (e.g., related to gender, country, continent), these are ongoing efforts. The model may still reflect existing societal biases present in the training data. Results should be interpreted as insights, not definitive truths.\n",
        "- **Statistical Tool**: This model is a statistical tool; individual situations are unique and cannot be fully captured by a generalized model.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "st.subheader(\"Our Commitment to Fairness\")\n",
        "st.write(\"\"\"\n",
        "We are committed to building fair and transparent AI systems. Our process includes:\n",
        "- **Identifying Sensitive Attributes**: We explicitly analyze features like Gender, Country, and Continent for potential biases.\n",
        "- **Quantifying Bias**: We measure disparities in predictions across different demographic groups using various fairness metrics.\n",
        "- **Implementing Mitigation Strategies**: We've explored and implemented techniques like post-processing output adjustment (e.g., based on Gender) to reduce observed biases in predictions.\n",
        "- **Transparency**: We aim to be transparent about our methods and the limitations of our model, encouraging users to interpret results critically.\n",
        "\n",
        "We believe that understanding and addressing bias is a continuous journey, and we welcome feedback to improve our model's fairness and accuracy.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "st.subheader(\"Contact & Feedback\")\n",
        "st.write(\"\"\"\n",
        "We value your feedback! If you have any questions, suggestions, or encounter issues, please feel free to reach out.\n",
        "\"\"\"\n",
        ")\n",
        "st.markdown(\"Email: [support@globalpayinsight.com](mailto:support@globalpayinsight.com)\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting pages/3_About_Our_Model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the public IP address of the Colab runtime\n",
        "!curl ifconfig.me"
      ],
      "metadata": {
        "id": "JUvIFdESjeMl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5620161-a8c5-4255-e918-ab726f0ac0ff"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.168.51.195"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "uiGQqkRKjhOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc983c57-3a6e-491e-b80a-560584d6250e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.168.51.195:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0Kyour url is: https://public-squids-wonder.loca.lt\n"
          ]
        }
      ]
    }
  ]
}